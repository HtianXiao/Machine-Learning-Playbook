{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x,0)\n",
    "def sigmoid(x):\n",
    "    if (x>0).all():\n",
    "        return 1.0/(1+np.exp(-x))\n",
    "    else:\n",
    "        return np.exp(x)/(1+np.exp(x))\n",
    "def plot_decision_boundary(W, b, X, Y):\n",
    "    x_min, x_max = X[0,:].min(), X[0,:].max()  #取得绘图数值范围\n",
    "    y_min, y_max = X[1,:].min(), X[1,:].max()\n",
    "    step = 0.01   #网格精度\n",
    "    xx,yy = np.meshgrid( np.arange(x_min,x_max,step), np.arange(y_min,y_max,step) )  #生成一张网格\n",
    "    plot_samples = np.array( [xx.ravel(),yy.ravel()] )\n",
    "    A = plot_samples.copy()\n",
    "    for l in range(1, len(W)):\n",
    "        Z = np.dot(W[l], A)+b[l]\n",
    "        if l==len(W)-1:\n",
    "            A = sigmoid(Z)\n",
    "        else:\n",
    "            A = relu(Z)\n",
    "    A[A>0.5] = 1\n",
    "    A[A<=0.5] = 0\n",
    "    A =A.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, A, cmap=plt.cm.Spectral)\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('y2')\n",
    "    plt.scatter(X[0,:], X[1,:], c=Y[0,:])\n",
    "    plt.show()\n",
    "    \n",
    "def load_2D_dataset(is_plot=True):\n",
    "    data = sio.loadmat('data.mat')\n",
    "    train_X = data['X'].T\n",
    "    train_Y = data['y'].T\n",
    "    test_X = data['Xval'].T\n",
    "    test_Y = data['yval'].T\n",
    "    if is_plot:\n",
    "        plt.scatter(train_X[0, :], train_X[1, :], c=train_Y[0,:], s=40, cmap=plt.cm.Spectral);\n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nn_utils \n",
    "train_x,train_y,test_x,test_y = nn_utils.load_2D_dataset()#导入数据\n",
    "nTrain = train_x.shape[1]\n",
    "nTest = test_x.shape[1]\n",
    "#初始化超参数----------------------------------------\n",
    "layers = [train_x.shape[0], 50, 35, 20, 10, 1]  #网络结构\n",
    "alpha = 0.02  #学习率\n",
    "drop_prob = 0.6   #神经元保留概率\n",
    "Iterations = 40000  #迭代次数\n",
    "nLayers = len(layers)-1 #网络层数\n",
    "#初始化W,b-------------------------------------------\n",
    "W = [[] for i in range(nLayers+1)]\n",
    "b = [[] for i in range(nLayers+1)]\n",
    "for l in range(1,nLayers+1):\n",
    "    W[l] = np.random.randn(layers[l],layers[l-1])/(np.sqrt(layers[l-1]/2))\n",
    "    b[l] = np.zeros((layers[l],1))\n",
    "dW = W.copy()\n",
    "db = b.copy()\n",
    "#初始化Cache-----------------------------------------\n",
    "A = [[] for i in range(nLayers+1)]\n",
    "Z = [[] for i in range(nLayers+1)]\n",
    "for l in range(1,nLayers+1):\n",
    "    A[l] = np.zeros((layers[l],nTrain))\n",
    "    Z[l] = np.zeros((layers[l],nTrain))\n",
    "    print(A[l].shape)\n",
    "    print(Z[l].shape)\n",
    "dA = A.copy()\n",
    "dZ = Z.copy()\n",
    "D = A.copy()  #drop矩阵\n",
    "A[0] = train_x\n",
    "cost = []\n",
    "#迭代训练-------------------------------------------------\n",
    "for i in range(Iterations):\n",
    "    for l in range(1,nLayers+1):  #前向传播\n",
    "        Z[l] = np.dot(W[l],A[l-1])+b[l]  \n",
    "        if l==nLayers:\n",
    "            A[l] = nn_utils.sigmoid(Z[l])  \n",
    "        else:\n",
    "            A[l] = nn_utils.relu(Z[l])\n",
    "            D[l] = np.random.rand(A[l].shape[0],A[l].shape[1])<drop_prob\n",
    "            A[l] = A[l]*D[l]   #随机丢弃部分神经元 简化网络\n",
    "            A[l] /= drop_prob\n",
    "    dZ[nLayers] = (A[nLayers]-train_y)/nTrain\n",
    "    for l in np.arange(nLayers,0,-1):\n",
    "        dW[l] = np.dot(dZ[l], A[l-1].T)\n",
    "        db[l] = np.sum(dZ[l], axis=1, keepdims=True)\n",
    "        if l>1:\n",
    "            dA[l-1] = np.dot(W[l].T, dZ[l])*D[l-1]\n",
    "            dA[l-1] /= drop_prob\n",
    "            dZ[l-1] = dA[l-1].copy()\n",
    "            dZ[l-1][Z[l-1]<0] = 0\n",
    "    for l in range(1,nLayers+1):\n",
    "        W[l] -=alpha*dW[l]\n",
    "        b[l] -= alpha*db[l]\n",
    "    if i%2000==0:\n",
    "        cost_cur = -np.sum( train_y*np.log(A[nLayers]+0.0001)+(1-train_y)*np.log(1-A[nLayers]+0.0001) )/nTrain\n",
    "        cost.append(cost_cur)\n",
    "        print(\"迭代次数：\"+str(i)+\"---cost：\"+str(cost_cur))        \n",
    "\n",
    "#计算精度-------------------------------------------------\n",
    "train_err = np.sum(A[nLayers][train_y==1]<=0.5)+np.sum(A[nLayers][train_y==0]>=0.5)\n",
    "print(\"训练正确率：\"+str(1-train_err/nTrain))\n",
    "predict_A = test_x\n",
    "for l in range(1,nLayers+1):\n",
    "    predict_Z = np.dot(W[l], predict_A)+b[l]\n",
    "    if l==nLayers:\n",
    "        predict_A = nn_utils.sigmoid(predict_Z)\n",
    "    else:\n",
    "        predict_A = nn_utils.relu(predict_Z)\n",
    "test_err = np.sum(predict_A[test_y==1]<=0.5)+np.sum(predict_A[test_y==0]>0.5)\n",
    "print(\"测试错误率：\"+str(1-test_err/nTest))\n",
    "nn_utils.plot_decision_boundary(W, b, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
